#!/bin/bash
#
# This script will export all essential data from the old database.

. /var/ida/update/init.sh

# Ensure DBDATA is defined in configuration, and that the subdirectory exists
if [[ -z "$DBDATA" ]]; then
  echo "Error: Environment variable DBDATA must be defined" >&2
  exit 1
fi
if [[ ! -d "$DBDATA" ]]; then
  mkdir -p "$DBDATA" || { echo "Error: Failed to create directory $DBDATA" >&2; exit 1; }
fi

if [ "$1" = "--test" ]; then
    echo "TEST MODE: Data will be extracted from new database!"
    DBNAME_OLD="$DBNAME_NEW"
    OC_IDA_ACTION_FIELDS="$OC_IDA_ACTION_FIELDS_TEST"
fi

set -e # if anything fails, die die die

#------------------------------------------------------------------------------------------------------------------------

echo "Exporting essential data from $DBNAME_OLD ..."

# NOTES:
# 
# When exporting account related data, we exclude the admin user account and group.
#
# When Nextcloud is installed, storage 1 is created for the admin user account and storage 2 corresponds to 
# the data root. All new users get storage ids starting from 3, so when exporting from oc_filecache and
# oc_mounts, we limit data to storage ids greater than 2.
# 
# Copying of records in oc_filecache_extended is where we may get some collisions if we use a brute
# force approach that copies everything, as it will include the default files belonging to admin, unless we
# first get the fileid values of all files belonging to admin and excluding them in the export query...
#
# The table oc_mounts has changed and now requires the class of the mount to be specified, e.g. whether
# local or shared. Need to clarify how best to handle this. It may be that we only copy mounts for PSO users and
# brute force inject the correct class for local mounts -- then reshare the frozen and staging folders to all
# project users, which will add database entries for those sharea mounts accordingly.

export PGPASSWORD="$DBROPASSWORD"

PSQL="psql -h $DBHOST -p $DBPORT -d $DBNAME_OLD -U $DBROUSER"

EXPORT_ARGS="FORMAT CSV, HEADER TRUE, DELIMITER ',', QUOTE '\"', ESCAPE '\"', FORCE_QUOTE *, ENCODING 'UTF8'"

function export_table() {
    local table="$1"
    local fields="$2"
    local filter="${3:-}"
    local csv_file="${DBDATA}/${table}.csv"
    local err_file="${DBDATA}/${table}.err"
    echo "Exporting data from ${table} ..."
    local expected_record_count=$($PSQL -t -A -c "SELECT COUNT(*) FROM ${table} ${filter}")
    if [ "$expected_record_count" = "0" ]; then
        echo "Error: No matching records in ${table} with filter: ${filter}" >&2
        exit 1
    fi
    $PSQL -c "\COPY (SELECT ${fields} FROM ${table} ${filter}) TO STDOUT WITH ($EXPORT_ARGS)" > "$csv_file" 2> "$err_file"
    if [ -s "$err_file" ]; then
        echo "Error: Failed to export data from ${table}" >&2
        cat "$err_file" >&2
        exit 1
    fi
    if [ ! -f "$csv_file" ]; then
        echo "Error: The output file ${csv_file} does not exist" >&2
        exit 1
    fi
    local exported_record_count=$(/var/ida/update/count-csv-records < "${csv_file}")
    if [ "$exported_record_count" = "0" ]; then
        echo "Error: The output file ${csv_file} is empty" >&2
        exit 1
    fi
    if [ "$exported_record_count" != "$expected_record_count" ]; then
        echo "Error: Failed to export exactly ${expected_record_count} expected records from ${table}: exported ${exported_record_count} records" >&2
        exit 1
    fi
}

# Get list of fileids for all files belonging to admin (storage 1), and exclude them from the oc_filecache_extended export query
EXCLUDED_FILEIDS=$($PSQL -t -A -c "SELECT fileid FROM oc_filecache WHERE storage = 1" | tr '\n' ',' | sed 's/,$//')
if [[ -z "$EXCLUDED_FILEIDS" ]]; then
    OC_FILECACHE_EXTENDED_FILTER=""
else
    OC_FILECACHE_EXTENDED_FILTER="WHERE fileid NOT IN (${EXCLUDED_FILEIDS})"
fi

# Export details for storages with id > 2, which excludes admin and data root
# From filecache only export records pertaining to files
# Only export group shares (type 2) and exclude shares owned by admin
# For all tables, where relevant, exclude admin records

export_table "oc_mimetypes"          "$OC_MIMETYPES_FIELDS"
export_table "oc_mounts"             "$OC_MOUNTS_FIELDS"             "WHERE storage_id > 2"
export_table "oc_storages"           "$OC_STORAGES_FIELDS"           "WHERE id LIKE 'home::%' AND id <> 'home::admin'"
export_table "oc_accounts"           "$OC_ACCOUNTS_FIELDS"           "WHERE uid <> 'admin'"
export_table "oc_accounts_data"      "$OC_ACCOUNTS_DATA_FIELDS"      "WHERE uid <> 'admin'"
export_table "oc_users"              "$OC_USERS_FIELDS"              "WHERE uid <> 'admin'"
export_table "oc_preferences"        "$OC_PREFERENCES_FIELDS"        "WHERE userid <> 'admin'"
export_table "oc_groups"             "$OC_GROUPS_FIELDS"             "WHERE gid <> 'admin'"
export_table "oc_group_user"         "$OC_GROUP_USER_FIELDS"         "WHERE uid <> 'admin'"
export_table "oc_share"              "$OC_SHARE_FIELDS"              "WHERE share_type = 2 AND uid_owner <> 'admin'"
export_table "oc_filecache"          "$OC_FILECACHE_FIELDS"          "WHERE storage > 2 AND path LIKE 'files/%'"
export_table "oc_filecache_extended" "$OC_FILECACHE_EXTENDED_FIELDS" "$OC_FILECACHE_EXTENDED_FILTER"
export_table "oc_ida_action"         "$OC_IDA_ACTION_FIELDS"
export_table "oc_ida_frozen_file"    "$OC_IDA_FROZEN_FILE_FIELDS"
export_table "oc_ida_data_change"    "$OC_IDA_DATA_CHANGE_FIELDS"

echo "Exporting completed."

ls -l "$DBDATA"/*.csv
